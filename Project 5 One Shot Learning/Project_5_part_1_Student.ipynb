{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ep1Ky-nDBZIr"
   },
   "source": [
    "You might need to modify the third line in the code cell below, to make sure you cd to the actual directory which your ipynb file is located in.\n",
    "\n",
    "**Caution**: due to the nature of this project's setup, everytime you want to rerun some code cell below, please click **Runtime -> Restart and run all**; this operation clears the computational graphs and the local variables but allow training and testing data that are already loaded from google drive to stay in the colab runtime space. Please do **not** do the following if you just wish to rerun code: click Runtime -> reset all runtimes, and then click Runtime -> Run all; it will remount your google drive, and remove the training and testing data already loaded in your colab runtime space. **Runtime -> Restart and run all** automatically avoids remounting the drive after the first time you run the notebook file; the loaded data can usually stay in your colab runtime space for many hours.\n",
    "\n",
    "Loading the training and testing data after remounting your google drive takes 30 - 40 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7sWni0FseVUz"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/gdrive/\", force_remount=True)\n",
    "# %cd gdrive/My Drive/Neural_Turing_Machine/NTM_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9gdekJg_-xa"
   },
   "outputs": [],
   "source": [
    "from utils import OmniglotDataLoader, one_hot_decode, five_hot_decode\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import numpy as np\n",
    "# %tensorflow_version 1.x\n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "otNm4yidAQQB"
   },
   "source": [
    "Already implemented, no need to change.\n",
    "\n",
    "This class is part of the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZTXPodW_5_i"
   },
   "outputs": [],
   "source": [
    "class NTMOneShotLearningModel():\n",
    "  def __init__(self, model, n_classes, batch_size, seq_length, image_width, image_height,\n",
    "                rnn_size, num_memory_slots, rnn_num_layers, read_head_num, write_head_num, memory_vector_dim, learning_rate):\n",
    "    self.output_dim = n_classes\n",
    "\n",
    "    # Note: the images are flattened to 1D tensors\n",
    "    # The input data structure is of the following form:\n",
    "    # self.x_image[i,j,:] = jth image in the ith sequence (or, episode)\n",
    "    self.x_image = tf.placeholder(dtype=tf.float32, shape=[batch_size, seq_length, image_width * image_height])\n",
    "    # Model's output label is one-hot encoded\n",
    "    # The data structure is of the following form:\n",
    "    # self.x_label[i,j,:] = one-hot label of the jth image in \n",
    "    #             the ith sequence (or, episode)\n",
    "    self.x_label = tf.placeholder(dtype=tf.float32, shape=[batch_size, seq_length, self.output_dim])\n",
    "    # Target label is one-hot encoded\n",
    "    self.y = tf.placeholder(dtype=tf.float32, shape=[batch_size, seq_length, self.output_dim])\n",
    "    \n",
    "    # The dense layer for mapping controller output and retrieved\n",
    "    # memory content to classification labels\n",
    "    self.controller_output_to_ntm_output = tf.keras.layers.Dense(units=self.output_dim, use_bias=True)\n",
    "\n",
    "    if model == 'LSTM':\n",
    "      # Using a LSTM layer to serve as the controller, no memory\n",
    "      def rnn_cell(rnn_size):\n",
    "        return tf.nn.rnn_cell.BasicLSTMCell(rnn_size)\n",
    "      cell = tf.nn.rnn_cell.MultiRNNCell([rnn_cell(rnn_size) for _ in range(rnn_num_layers)])\n",
    "      state = cell.zero_state(batch_size=batch_size, dtype=tf.float32)\n",
    "    \n",
    "    # Initialize the controller model, including wiping its memory\n",
    "    # Also, get the initial state of the MANN model\n",
    "    \n",
    "    self.state_list = [state]\n",
    "    # Setup the NTM's output\n",
    "    self.o = []\n",
    "    \n",
    "    # Now iterate over every sample in the sequence \n",
    "    for t in range(seq_length):\n",
    "      output, state = cell(tf.concat([self.x_image[:, t, :], self.x_label[:, t, :]], axis=1), state)\n",
    "      # Map controller output (with retrieved memory) + current (offseted) label \n",
    "      # to the overall ntm's output with an affine operation\n",
    "      # The output is the classification labels\n",
    "      output = self.controller_output_to_ntm_output(output)\n",
    "      output = tf.nn.softmax(output, axis=1)\n",
    "      self.o.append(output)\n",
    "      self.state_list.append(state)\n",
    "    # post-process the output of the classifier\n",
    "    self.o = tf.stack(self.o, axis=1)\n",
    "    self.state_list.append(state)\n",
    "\n",
    "    eps = 1e-8\n",
    "    # cross entropy, between model output labels and target labels\n",
    "    self.learning_loss = -tf.reduce_mean(  \n",
    "        tf.reduce_sum(self.y * tf.log(self.o + eps), axis=[1, 2])\n",
    "    )\n",
    "    \n",
    "    self.o = tf.reshape(self.o, shape=[batch_size, seq_length, -1])\n",
    "    self.learning_loss_summary = tf.summary.scalar('learning_loss', self.learning_loss)\n",
    "\n",
    "    with tf.variable_scope('optimizer'):\n",
    "      self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "      self.train_op = self.optimizer.minimize(self.learning_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_qMlbTWAvg0"
   },
   "source": [
    "The training and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Se1yEaxmey6Z"
   },
   "outputs": [],
   "source": [
    "def train(learning_rate, image_width, image_height, n_train_classes, n_test_classes, restore_training, \\\n",
    "         num_epochs, n_classes, batch_size, seq_length, num_memory_slots, augment, save_dir, model_path, tensorboard_dir):\n",
    "\n",
    "  # We always use one-hot encoding of the labels in this experiment\n",
    "  label_type = \"one_hot\"\n",
    "\n",
    "  # Initialize the model\n",
    "  model = NTMOneShotLearningModel(model=model_path, n_classes=n_classes,\\\n",
    "                    batch_size=batch_size, seq_length=seq_length,\\\n",
    "                    image_width=image_width, image_height=image_height, \\\n",
    "                    rnn_size=rnn_size, num_memory_slots=num_memory_slots,\\\n",
    "                    rnn_num_layers=rnn_num_layers, read_head_num=read_head_num,\\\n",
    "                    write_head_num=write_head_num, memory_vector_dim=memory_vector_dim,\\\n",
    "                    learning_rate=learning_rate)\n",
    "  print(\"Model initialized\")\n",
    "  data_loader = OmniglotDataLoader(\n",
    "      image_size=(image_width, image_height),\n",
    "      n_train_classses=n_train_classes,\n",
    "      n_test_classes=n_test_classes\n",
    "  )\n",
    "  print(\"Data loaded\")\n",
    "  # Note: our training loop is in the tensorflow 1.x style\n",
    "  with tf.Session() as sess:\n",
    "    if restore_training:\n",
    "      saver = tf.train.Saver()\n",
    "      ckpt = tf.train.get_checkpoint_state(save_dir + '/' + model_path)\n",
    "      saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "      saver = tf.train.Saver(tf.global_variables())\n",
    "      tf.global_variables_initializer().run()\n",
    "    train_writer = tf.summary.FileWriter(tensorboard_dir + '/' + model_path, sess.graph)\n",
    "    print(\"1st\\t2nd\\t3rd\\t4th\\t5th\\t6th\\t7th\\t8th\\t9th\\t10th\\tepoch\\tloss\")\n",
    "    for b in range(num_epochs):\n",
    "      # Test the model\n",
    "      if b % 100 == 0:\n",
    "        # Note: the images are flattened to 1D tensors\n",
    "        # The input data structure is of the following form:\n",
    "        # x_image[i,j,:] = jth image in the ith sequence (or, episode)\n",
    "        # And the sequence of 50 images x_image[i,:,:] constitute\n",
    "        # one episode, and each class (out of 5 classes) has around 10\n",
    "        # appearances in this sequence, as seq_length = 50 and \n",
    "        # n_classes = 5, as specified in the code block below\n",
    "        # See the details in utils.py, OmniglotDataLoader class\n",
    "        x_image, x_label, y = data_loader.fetch_batch(n_classes, batch_size, seq_length,\n",
    "                                  type='test',\n",
    "                                  augment=augment,\n",
    "                                  label_type=label_type)\n",
    "        feed_dict = {model.x_image: x_image, model.x_label: x_label, model.y: y}\n",
    "        output, learning_loss = sess.run([model.o, model.learning_loss], feed_dict=feed_dict)\n",
    "        merged_summary = sess.run(model.learning_loss_summary, feed_dict=feed_dict)\n",
    "        train_writer.add_summary(merged_summary, b)\n",
    "        accuracy = test(batch_size,seq_length, y, output)\n",
    "        for accu in accuracy:\n",
    "          print('%.4f' % accu, end='\\t')\n",
    "        print('%d\\t%.4f' % (b, learning_loss))\n",
    "\n",
    "      # Save model per 2000 epochs\n",
    "      if b%2000==0 and b>0:\n",
    "        saver.save(sess, save_dir + '/' + model_path + '/model.tfmodel', global_step=b)\n",
    "\n",
    "      # Train the model\n",
    "      x_image, x_label, y = data_loader.fetch_batch(n_classes, batch_size, seq_length, \\\n",
    "                                type='train',\n",
    "                                augment=augment,\n",
    "                                label_type=label_type)\n",
    "      feed_dict = {model.x_image: x_image, model.x_label: x_label, model.y: y}\n",
    "      sess.run(model.train_op, feed_dict=feed_dict)\n",
    "\n",
    "# Fill in this function. You might not need seq_length (the length of an episode)\n",
    "# as an input, depending on your setup \n",
    "# Note: y is the true labels, and of shape (batch_size, seq_length, 5)\n",
    "# output is the network's classification labels\n",
    "def test(batch_size,seq_length, y, output):\n",
    "  # Fill in\n",
    "  decoded_y = one_hot_decode(y)\n",
    "  decoded_out = one_hot_decode(output)\n",
    "  correct = np.zeros(seq_length)\n",
    "  total = np.zeros(seq_length)\n",
    "  for i in range(batch_size):\n",
    "    # ith episode\n",
    "    yi = decoded_y[i,:]\n",
    "    outi = decoded_out[i,:]\n",
    "    count = {}\n",
    "    for j in range(seq_length):\n",
    "      if yi[j] not in count:\n",
    "        count[yi[j]] = 0\n",
    "      count[yi[j]] += 1\n",
    "      total[count[yi[j]]] += 1\n",
    "      if  yi[j] == outi[j]: \n",
    "        correct[count[yi[j]]] += 1\n",
    "  return [float(correct[i]) / total[i] if total[i] > 0. else 0. for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VruOInLHkZUK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-eb58e367ca65>:25: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "Model initialized\n",
      "Entered Dataloader\n",
      "10.0% data loaded.\n",
      "20.0% data loaded.\n",
      "30.0% data loaded.\n",
      "40.0% data loaded.\n",
      "50.0% data loaded.\n",
      "60.0% data loaded.\n",
      "70.0% data loaded.\n",
      "80.0% data loaded.\n",
      "90.0% data loaded.\n",
      "100.0% data loaded.\n",
      "Data loaded\n",
      "1st\t2nd\t3rd\t4th\t5th\t6th\t7th\t8th\t9th\t10th\tepoch\tloss\n",
      "0.1875\t0.1875\t0.1750\t0.1250\t0.1750\t0.2051\t0.1918\t0.1364\t0.2000\t0.2553\t0\t80.6996\n",
      "0.1500\t0.2000\t0.1500\t0.2250\t0.2278\t0.2727\t0.2105\t0.1667\t0.1852\t0.2000\t100\t80.5079\n",
      "0.2125\t0.1875\t0.2000\t0.2000\t0.1948\t0.2568\t0.1972\t0.2000\t0.2069\t0.2128\t200\t80.4981\n",
      "0.1750\t0.1625\t0.1500\t0.2500\t0.2308\t0.1867\t0.2740\t0.2319\t0.1346\t0.3182\t300\t80.5099\n",
      "0.2375\t0.1500\t0.2625\t0.1875\t0.1899\t0.2436\t0.2254\t0.2586\t0.3077\t0.1489\t400\t80.4048\n",
      "0.1875\t0.1750\t0.1625\t0.1772\t0.1266\t0.2338\t0.2083\t0.1571\t0.2542\t0.2128\t500\t80.5534\n",
      "0.2125\t0.1625\t0.2250\t0.1250\t0.2308\t0.1795\t0.2254\t0.1935\t0.2857\t0.2979\t600\t80.4532\n",
      "0.1875\t0.2375\t0.2125\t0.1392\t0.1410\t0.2027\t0.1549\t0.2063\t0.2143\t0.1395\t700\t80.5082\n",
      "0.2250\t0.2000\t0.1500\t0.1250\t0.2179\t0.1944\t0.1493\t0.1774\t0.1400\t0.2128\t800\t80.3707\n",
      "0.1375\t0.1875\t0.2000\t0.2500\t0.2436\t0.2105\t0.2353\t0.2857\t0.3137\t0.1463\t900\t80.4783\n",
      "0.1875\t0.1500\t0.1875\t0.2278\t0.1842\t0.1408\t0.1471\t0.1613\t0.0702\t0.1739\t1000\t80.6057\n",
      "0.2250\t0.2375\t0.2250\t0.1875\t0.2000\t0.2500\t0.2297\t0.2951\t0.3125\t0.1463\t1100\t80.4859\n",
      "0.2125\t0.2250\t0.2000\t0.2000\t0.1795\t0.1579\t0.2113\t0.2419\t0.2157\t0.2766\t1200\t80.4444\n",
      "0.2625\t0.1625\t0.2500\t0.1625\t0.2308\t0.2133\t0.2174\t0.2923\t0.2281\t0.2857\t1300\t80.4011\n",
      "0.2000\t0.1625\t0.1875\t0.2405\t0.2237\t0.1622\t0.2319\t0.1515\t0.2642\t0.1778\t1400\t80.4859\n",
      "0.2000\t0.2250\t0.2500\t0.1625\t0.2025\t0.1646\t0.1806\t0.2273\t0.2321\t0.2273\t1500\t80.4471\n",
      "0.1875\t0.2750\t0.2000\t0.2375\t0.2208\t0.1200\t0.2055\t0.1912\t0.1724\t0.1364\t1600\t80.4697\n",
      "0.2000\t0.2025\t0.1899\t0.1899\t0.1923\t0.2192\t0.2206\t0.2540\t0.1754\t0.1628\t1700\t80.4587\n",
      "0.2875\t0.2250\t0.3000\t0.1625\t0.2250\t0.1948\t0.2027\t0.1875\t0.1455\t0.2222\t1800\t80.4360\n",
      "0.2250\t0.1500\t0.2625\t0.2000\t0.3038\t0.2133\t0.2500\t0.1667\t0.1961\t0.1739\t1900\t80.4963\n",
      "0.1750\t0.1500\t0.1625\t0.1500\t0.1875\t0.2051\t0.2368\t0.2500\t0.2807\t0.1111\t2000\t80.4424\n",
      "0.1500\t0.2500\t0.1875\t0.2785\t0.2436\t0.1688\t0.2222\t0.1912\t0.1207\t0.1522\t2100\t80.4898\n",
      "0.1625\t0.2375\t0.2125\t0.1750\t0.2625\t0.2125\t0.1781\t0.2000\t0.1754\t0.2045\t2200\t80.4779\n",
      "0.1875\t0.1375\t0.2250\t0.1410\t0.2436\t0.2027\t0.1429\t0.1406\t0.2632\t0.2553\t2300\t80.4517\n",
      "0.2125\t0.1875\t0.1750\t0.2125\t0.1923\t0.1316\t0.1667\t0.2188\t0.2000\t0.2143\t2400\t80.4853\n",
      "0.1625\t0.1625\t0.2375\t0.2152\t0.1899\t0.2208\t0.2083\t0.1905\t0.2321\t0.1860\t2500\t80.4832\n",
      "0.1750\t0.2000\t0.1750\t0.1750\t0.2025\t0.1948\t0.1549\t0.2000\t0.1579\t0.1429\t2600\t80.5530\n",
      "0.2500\t0.2375\t0.2250\t0.1500\t0.2625\t0.2078\t0.1781\t0.2462\t0.2182\t0.1556\t2700\t80.4694\n",
      "0.1750\t0.1625\t0.1750\t0.2125\t0.2152\t0.1974\t0.1970\t0.1333\t0.1455\t0.2045\t2800\t80.5598\n",
      "0.2000\t0.1500\t0.2000\t0.1772\t0.1948\t0.2208\t0.1000\t0.1475\t0.0784\t0.1395\t2900\t80.4873\n",
      "0.2250\t0.1875\t0.1750\t0.2000\t0.2025\t0.2027\t0.1471\t0.2419\t0.2037\t0.2143\t3000\t80.5328\n",
      "0.2375\t0.2500\t0.2625\t0.2750\t0.2405\t0.2405\t0.2105\t0.2206\t0.1897\t0.2432\t3100\t80.3668\n",
      "0.2250\t0.1500\t0.2000\t0.1375\t0.1875\t0.1688\t0.1842\t0.2769\t0.0980\t0.1522\t3200\t80.4824\n",
      "0.1625\t0.2125\t0.2152\t0.1899\t0.1538\t0.1818\t0.1507\t0.1515\t0.1961\t0.2000\t3300\t80.5213\n",
      "0.1750\t0.2625\t0.1250\t0.1625\t0.2152\t0.1795\t0.1268\t0.2273\t0.1525\t0.2200\t3400\t80.4930\n",
      "0.2000\t0.2000\t0.2000\t0.1875\t0.1923\t0.2078\t0.2143\t0.2419\t0.2222\t0.2917\t3500\t80.4718\n",
      "0.2125\t0.1875\t0.2025\t0.2025\t0.2051\t0.2133\t0.2254\t0.1791\t0.2364\t0.2391\t3600\t80.5259\n",
      "0.2750\t0.1875\t0.1899\t0.1899\t0.1538\t0.2208\t0.1389\t0.1846\t0.2857\t0.2553\t3700\t80.4192\n",
      "0.1500\t0.1750\t0.2375\t0.2000\t0.1948\t0.1974\t0.2286\t0.1452\t0.1579\t0.2143\t3800\t80.4544\n",
      "0.2125\t0.1875\t0.2625\t0.2250\t0.1875\t0.2338\t0.3014\t0.1970\t0.1905\t0.2917\t3900\t80.4508\n",
      "0.1500\t0.1875\t0.2250\t0.1875\t0.2152\t0.2237\t0.2361\t0.2154\t0.1698\t0.1778\t4000\t80.4707\n",
      "0.1625\t0.2375\t0.1875\t0.1875\t0.1266\t0.2192\t0.2000\t0.3182\t0.2453\t0.2340\t4100\t80.5543\n",
      "0.1500\t0.1875\t0.1750\t0.1875\t0.2051\t0.2727\t0.1690\t0.1129\t0.2182\t0.2609\t4200\t80.5051\n",
      "0.1500\t0.1750\t0.1750\t0.1375\t0.1282\t0.1667\t0.1507\t0.2154\t0.1579\t0.2500\t4300\t80.5294\n",
      "0.2375\t0.1875\t0.2625\t0.1500\t0.2405\t0.2432\t0.2192\t0.2500\t0.2069\t0.2609\t4400\t80.4237\n",
      "0.2125\t0.2375\t0.2875\t0.2250\t0.2208\t0.2105\t0.2174\t0.2424\t0.2264\t0.2619\t4500\t80.4292\n",
      "0.1875\t0.1875\t0.2500\t0.2500\t0.2375\t0.1667\t0.1806\t0.2273\t0.2692\t0.1591\t4600\t80.4762\n",
      "0.1875\t0.2250\t0.1625\t0.2125\t0.1538\t0.1733\t0.1286\t0.1846\t0.1724\t0.2041\t4700\t80.5119\n",
      "0.1750\t0.1875\t0.1750\t0.2000\t0.1646\t0.2597\t0.2361\t0.1692\t0.1754\t0.2051\t4800\t80.4824\n",
      "0.1625\t0.1500\t0.1250\t0.1923\t0.1538\t0.1795\t0.1429\t0.1111\t0.1406\t0.1429\t4900\t80.5458\n",
      "0.1625\t0.2000\t0.2250\t0.2564\t0.1818\t0.2000\t0.1690\t0.2712\t0.1538\t0.1163\t5000\t80.4800\n",
      "0.1375\t0.1625\t0.2278\t0.1139\t0.2308\t0.2208\t0.1644\t0.1618\t0.2632\t0.1556\t5100\t80.5196\n",
      "0.2625\t0.2000\t0.2625\t0.1875\t0.1899\t0.2895\t0.2639\t0.2121\t0.2400\t0.1190\t5200\t80.3397\n",
      "0.2375\t0.1750\t0.1875\t0.2000\t0.2152\t0.2763\t0.2192\t0.1746\t0.1897\t0.1364\t5300\t80.4396\n",
      "0.1375\t0.2125\t0.2250\t0.1875\t0.1899\t0.1818\t0.2055\t0.2059\t0.1754\t0.1489\t5400\t80.4399\n",
      "0.2000\t0.2625\t0.2125\t0.1625\t0.2500\t0.1923\t0.1972\t0.2000\t0.1667\t0.1702\t5500\t80.4875\n",
      "0.0875\t0.1375\t0.1375\t0.1519\t0.1818\t0.2162\t0.2286\t0.1719\t0.2143\t0.1667\t5600\t80.4882\n",
      "0.2875\t0.2875\t0.2250\t0.2375\t0.3038\t0.2785\t0.2113\t0.2239\t0.3036\t0.1087\t5700\t80.3979\n",
      "0.2000\t0.1625\t0.1875\t0.1875\t0.2375\t0.2500\t0.1594\t0.2131\t0.2000\t0.2500\t5800\t80.4995\n",
      "0.2000\t0.1875\t0.2000\t0.1875\t0.2208\t0.2105\t0.1884\t0.1695\t0.1569\t0.1951\t5900\t80.4597\n",
      "0.0875\t0.1250\t0.1125\t0.1125\t0.1899\t0.1667\t0.1351\t0.1061\t0.1207\t0.1875\t6000\t80.5453\n",
      "0.2375\t0.1875\t0.2375\t0.2308\t0.1818\t0.2000\t0.1644\t0.1935\t0.1887\t0.2391\t6100\t80.4233\n",
      "0.2125\t0.1625\t0.2278\t0.2405\t0.1667\t0.1867\t0.1667\t0.1587\t0.1579\t0.2273\t6200\t80.5101\n",
      "0.2000\t0.2500\t0.1750\t0.2000\t0.2179\t0.2308\t0.2105\t0.2239\t0.2115\t0.2791\t6300\t80.4579\n",
      "0.2375\t0.2250\t0.1875\t0.1500\t0.2051\t0.1974\t0.1618\t0.1452\t0.1636\t0.1522\t6400\t80.5171\n",
      "0.1750\t0.1625\t0.1875\t0.1875\t0.1646\t0.2368\t0.2714\t0.1562\t0.1897\t0.1600\t6500\t80.4589\n",
      "0.2000\t0.2375\t0.2125\t0.2250\t0.1772\t0.2308\t0.2466\t0.2143\t0.1404\t0.1250\t6600\t80.4327\n",
      "0.1625\t0.1625\t0.1750\t0.1772\t0.2436\t0.1948\t0.1944\t0.2000\t0.2182\t0.2558\t6700\t80.4359\n",
      "0.1875\t0.2375\t0.1750\t0.2625\t0.2000\t0.2179\t0.1528\t0.1692\t0.2321\t0.3000\t6800\t80.4815\n",
      "0.1750\t0.2000\t0.1750\t0.2000\t0.1750\t0.2278\t0.2778\t0.2969\t0.2308\t0.3409\t6900\t80.3407\n",
      "0.1625\t0.1875\t0.2125\t0.1750\t0.2532\t0.1948\t0.2286\t0.2308\t0.2241\t0.1702\t7000\t80.5303\n",
      "0.2125\t0.1000\t0.1750\t0.2278\t0.1899\t0.1711\t0.1831\t0.1765\t0.2778\t0.2708\t7100\t80.3831\n",
      "0.1375\t0.1750\t0.1875\t0.2250\t0.3125\t0.2468\t0.2800\t0.2239\t0.1724\t0.2340\t7200\t80.6101\n",
      "0.1750\t0.1875\t0.2375\t0.1875\t0.1266\t0.2000\t0.1714\t0.1525\t0.2549\t0.2222\t7300\t80.4841\n",
      "0.2250\t0.2000\t0.1875\t0.1875\t0.2375\t0.2179\t0.1200\t0.2714\t0.1167\t0.1395\t7400\t80.4718\n",
      "0.1875\t0.2000\t0.1625\t0.2532\t0.2051\t0.2179\t0.2500\t0.1831\t0.2203\t0.2195\t7500\t80.5500\n",
      "0.2000\t0.2000\t0.1750\t0.2125\t0.2000\t0.2692\t0.2267\t0.2031\t0.1400\t0.2558\t7600\t80.3475\n",
      "0.2750\t0.2750\t0.2125\t0.2278\t0.2532\t0.2400\t0.1857\t0.2121\t0.2364\t0.1395\t7700\t80.1901\n",
      "0.2375\t0.2750\t0.1875\t0.1625\t0.2532\t0.2817\t0.2239\t0.2459\t0.2182\t0.1905\t7800\t79.1141\n",
      "0.2125\t0.2750\t0.2532\t0.2308\t0.2692\t0.2973\t0.2687\t0.3333\t0.2830\t0.2889\t7900\t77.0455\n",
      "0.1625\t0.2500\t0.2875\t0.3544\t0.3671\t0.3974\t0.4110\t0.3134\t0.4068\t0.3750\t8000\t73.1971\n",
      "0.2500\t0.1875\t0.2785\t0.3418\t0.3077\t0.3378\t0.2941\t0.2951\t0.4000\t0.3778\t8100\t75.0043\n",
      "0.1875\t0.3250\t0.3375\t0.3375\t0.3250\t0.3289\t0.3768\t0.3485\t0.3898\t0.2979\t8200\t73.4450\n",
      "0.2000\t0.2625\t0.3418\t0.3671\t0.3846\t0.3117\t0.2429\t0.4531\t0.3962\t0.5000\t8300\t67.8522\n",
      "0.1375\t0.2625\t0.3625\t0.4250\t0.4684\t0.4675\t0.3889\t0.2903\t0.3036\t0.4468\t8400\t69.8599\n",
      "0.1250\t0.2500\t0.3875\t0.3462\t0.3462\t0.4400\t0.3380\t0.3939\t0.4407\t0.5000\t8500\t67.2647\n",
      "0.2375\t0.4000\t0.3375\t0.3875\t0.3125\t0.3797\t0.3684\t0.3731\t0.3214\t0.3478\t8600\t68.4898\n",
      "0.1875\t0.3625\t0.3875\t0.3250\t0.3875\t0.2857\t0.4247\t0.3231\t0.4000\t0.3800\t8700\t68.9761\n",
      "0.1750\t0.2875\t0.4250\t0.3875\t0.4103\t0.4231\t0.5616\t0.5397\t0.5283\t0.5435\t8800\t63.5346\n",
      "0.1625\t0.4000\t0.3875\t0.4557\t0.3816\t0.3816\t0.4324\t0.4603\t0.4423\t0.4419\t8900\t66.9272\n",
      "0.1625\t0.3250\t0.3500\t0.4250\t0.4125\t0.4000\t0.3944\t0.3438\t0.3962\t0.4186\t9000\t68.1649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1375\t0.3000\t0.4304\t0.5190\t0.4615\t0.4231\t0.4400\t0.4444\t0.5091\t0.3902\t9100\t63.5443\n",
      "0.1500\t0.3375\t0.3625\t0.4000\t0.4286\t0.4133\t0.4143\t0.3175\t0.4912\t0.4894\t9200\t67.2830\n",
      "0.1625\t0.3000\t0.3750\t0.5063\t0.4051\t0.4737\t0.3562\t0.4286\t0.3396\t0.4565\t9300\t66.6240\n",
      "0.1625\t0.4125\t0.4000\t0.4875\t0.4430\t0.4737\t0.5342\t0.5000\t0.4464\t0.4348\t9400\t63.8648\n",
      "0.2375\t0.2875\t0.4500\t0.4625\t0.4625\t0.5195\t0.4658\t0.5147\t0.3448\t0.5349\t9500\t62.5310\n",
      "0.1500\t0.3875\t0.5375\t0.4051\t0.4557\t0.4545\t0.4521\t0.4000\t0.4364\t0.5000\t9600\t63.6735\n",
      "0.2125\t0.3125\t0.3875\t0.4000\t0.4359\t0.4211\t0.5205\t0.4308\t0.4182\t0.5532\t9700\t64.8643\n",
      "0.1625\t0.4125\t0.4500\t0.4430\t0.4805\t0.4658\t0.4225\t0.5231\t0.4035\t0.4783\t9800\t61.4886\n",
      "0.2250\t0.3875\t0.4000\t0.4375\t0.4051\t0.4051\t0.4211\t0.5000\t0.3962\t0.4222\t9900\t63.3724\n",
      "0.1250\t0.4125\t0.4000\t0.4500\t0.4125\t0.4605\t0.4110\t0.4688\t0.3559\t0.4583\t10000\t65.8887\n",
      "0.2000\t0.3375\t0.4625\t0.5250\t0.4750\t0.5443\t0.4722\t0.4603\t0.4386\t0.5227\t10100\t60.2589\n",
      "0.2250\t0.2000\t0.3750\t0.3625\t0.5063\t0.4211\t0.4143\t0.5000\t0.3390\t0.3542\t10200\t67.8942\n",
      "0.1875\t0.4125\t0.4000\t0.5875\t0.4177\t0.4675\t0.4474\t0.4776\t0.5439\t0.5227\t10300\t62.4308\n",
      "0.1625\t0.4000\t0.5000\t0.4500\t0.4557\t0.4737\t0.6027\t0.5156\t0.5000\t0.5455\t10400\t59.1478\n",
      "0.1875\t0.3750\t0.4875\t0.4557\t0.5789\t0.4667\t0.4795\t0.4928\t0.4500\t0.5652\t10500\t63.9293\n",
      "0.2000\t0.3875\t0.4625\t0.5250\t0.5844\t0.4342\t0.4658\t0.5758\t0.5517\t0.5102\t10600\t60.8188\n",
      "0.1750\t0.3375\t0.4625\t0.4937\t0.4430\t0.3924\t0.4545\t0.5672\t0.6379\t0.6327\t10700\t61.3874\n",
      "0.2000\t0.3250\t0.3875\t0.4103\t0.4474\t0.4533\t0.4167\t0.5625\t0.4576\t0.5556\t10800\t65.0859\n",
      "0.2125\t0.3250\t0.4304\t0.5190\t0.4557\t0.5128\t0.4795\t0.5147\t0.5763\t0.5106\t10900\t59.7370\n",
      "0.1250\t0.4125\t0.5125\t0.5443\t0.5513\t0.4932\t0.6338\t0.6119\t0.4912\t0.5000\t11000\t59.9413\n",
      "0.1750\t0.4250\t0.3797\t0.4557\t0.4937\t0.5067\t0.4861\t0.5758\t0.5179\t0.5556\t11100\t59.6812\n",
      "0.1375\t0.4875\t0.5375\t0.5063\t0.5000\t0.4865\t0.5797\t0.5246\t0.6786\t0.6957\t11200\t56.1563\n",
      "0.1625\t0.5000\t0.4375\t0.5250\t0.5513\t0.5200\t0.5286\t0.6032\t0.5385\t0.6818\t11300\t58.5094\n",
      "0.1500\t0.4250\t0.4875\t0.5500\t0.5190\t0.6494\t0.6081\t0.6286\t0.6167\t0.7174\t11400\t54.2887\n",
      "0.1875\t0.4875\t0.6125\t0.5250\t0.6456\t0.5584\t0.6579\t0.5147\t0.5167\t0.7333\t11500\t51.6733\n",
      "0.2000\t0.3625\t0.5250\t0.5316\t0.4872\t0.5789\t0.6250\t0.6000\t0.5714\t0.6190\t11600\t57.1307\n",
      "0.1250\t0.4500\t0.5500\t0.5823\t0.5443\t0.5946\t0.6667\t0.6290\t0.6346\t0.4884\t11700\t53.8938\n",
      "0.1625\t0.4375\t0.5875\t0.6375\t0.6125\t0.5513\t0.5946\t0.4848\t0.6415\t0.6444\t11800\t54.0222\n",
      "0.2375\t0.4250\t0.5000\t0.5375\t0.6500\t0.6962\t0.6351\t0.6176\t0.6727\t0.5909\t11900\t52.0691\n",
      "0.1750\t0.5125\t0.6000\t0.6250\t0.5823\t0.6133\t0.6986\t0.6377\t0.6111\t0.6739\t12000\t50.2929\n",
      "0.1875\t0.4750\t0.5875\t0.6500\t0.7215\t0.7013\t0.6849\t0.7097\t0.6038\t0.7174\t12100\t49.0328\n",
      "0.2250\t0.5250\t0.5823\t0.6835\t0.6835\t0.6883\t0.6528\t0.5077\t0.7719\t0.7556\t12200\t47.9938\n",
      "0.1500\t0.5316\t0.6154\t0.6282\t0.5844\t0.6184\t0.7206\t0.6190\t0.6842\t0.7333\t12300\t51.0864\n",
      "0.2000\t0.4750\t0.6375\t0.6125\t0.6282\t0.7013\t0.6533\t0.7761\t0.6610\t0.7674\t12400\t48.5412\n",
      "0.2750\t0.5125\t0.5750\t0.6375\t0.6709\t0.5316\t0.6316\t0.6984\t0.6727\t0.6047\t12500\t51.1406\n",
      "0.2125\t0.4875\t0.6375\t0.5375\t0.5949\t0.6447\t0.6761\t0.6129\t0.6545\t0.6522\t12600\t51.0905\n",
      "0.2250\t0.5500\t0.6000\t0.5750\t0.6456\t0.6623\t0.5467\t0.7042\t0.7213\t0.6591\t12700\t48.9209\n",
      "0.1625\t0.4375\t0.5625\t0.5625\t0.5823\t0.6000\t0.6027\t0.6061\t0.6491\t0.7500\t12800\t51.8705\n",
      "0.1750\t0.4625\t0.5750\t0.6203\t0.7368\t0.7671\t0.6812\t0.6190\t0.7170\t0.7692\t12900\t47.0648\n",
      "0.1375\t0.4875\t0.6125\t0.6923\t0.6711\t0.6351\t0.6571\t0.6562\t0.7037\t0.6122\t13000\t49.8700\n",
      "0.3000\t0.5000\t0.5696\t0.6282\t0.7105\t0.7162\t0.7391\t0.6923\t0.6296\t0.7949\t13100\t48.2736\n",
      "0.1875\t0.5875\t0.5500\t0.6125\t0.6125\t0.6282\t0.6197\t0.6176\t0.6842\t0.5952\t13200\t49.7536\n",
      "0.1750\t0.4750\t0.6500\t0.6750\t0.6667\t0.6154\t0.7027\t0.6719\t0.7455\t0.6739\t13300\t50.0729\n",
      "0.2125\t0.5000\t0.6250\t0.6500\t0.6282\t0.6438\t0.6154\t0.6897\t0.7358\t0.8043\t13400\t48.0151\n",
      "0.1875\t0.5500\t0.7000\t0.7342\t0.6962\t0.7368\t0.7162\t0.6471\t0.7679\t0.6136\t13500\t42.9596\n",
      "0.2250\t0.5750\t0.5625\t0.5696\t0.6026\t0.6234\t0.7083\t0.6061\t0.6545\t0.6739\t13600\t49.7185\n",
      "0.2000\t0.5000\t0.5625\t0.6456\t0.6076\t0.6579\t0.6901\t0.6818\t0.7119\t0.7660\t13700\t47.5808\n",
      "0.2125\t0.5625\t0.5750\t0.6625\t0.7089\t0.7051\t0.6400\t0.7826\t0.7115\t0.6250\t13800\t47.3216\n",
      "0.2000\t0.5125\t0.6875\t0.7375\t0.7564\t0.7403\t0.6389\t0.7031\t0.7193\t0.6200\t13900\t45.2431\n",
      "0.1750\t0.5875\t0.5500\t0.6750\t0.6709\t0.6154\t0.6667\t0.7188\t0.6727\t0.7045\t14000\t46.5443\n",
      "0.2125\t0.5250\t0.7875\t0.6835\t0.7821\t0.6842\t0.6892\t0.7302\t0.6552\t0.7083\t14100\t43.1513\n",
      "0.1875\t0.5250\t0.6500\t0.7375\t0.6750\t0.6842\t0.6761\t0.8333\t0.7321\t0.7826\t14200\t43.4848\n",
      "0.1375\t0.5625\t0.5875\t0.6250\t0.7722\t0.6447\t0.7183\t0.7385\t0.7091\t0.6531\t14300\t45.9683\n",
      "0.2250\t0.5125\t0.7215\t0.7013\t0.6364\t0.6351\t0.6620\t0.6912\t0.7049\t0.6596\t14400\t46.8069\n",
      "0.2750\t0.5750\t0.6375\t0.7875\t0.6250\t0.6667\t0.6618\t0.6212\t0.7049\t0.7647\t14500\t44.3978\n",
      "0.1875\t0.5125\t0.7000\t0.5949\t0.7436\t0.7123\t0.7083\t0.7143\t0.7170\t0.7907\t14600\t44.3299\n",
      "0.2500\t0.4750\t0.6125\t0.6076\t0.6329\t0.7200\t0.6528\t0.7258\t0.6182\t0.7442\t14700\t47.1119\n",
      "0.2625\t0.5500\t0.6000\t0.6625\t0.7875\t0.7564\t0.7703\t0.7500\t0.7097\t0.7391\t14800\t43.9297\n",
      "0.1500\t0.5250\t0.6750\t0.5500\t0.6962\t0.6974\t0.7027\t0.7910\t0.6981\t0.7368\t14900\t45.8068\n",
      "0.1750\t0.6375\t0.6375\t0.6203\t0.6753\t0.7467\t0.7260\t0.7143\t0.6667\t0.7800\t15000\t41.6353\n",
      "0.2500\t0.5500\t0.6000\t0.6875\t0.6625\t0.7089\t0.7432\t0.6562\t0.8000\t0.7556\t15100\t45.0754\n",
      "0.2125\t0.6000\t0.6625\t0.6125\t0.7436\t0.6757\t0.7746\t0.6901\t0.7719\t0.6957\t15200\t44.0709\n",
      "0.2000\t0.6375\t0.6375\t0.6329\t0.6923\t0.6667\t0.7246\t0.7419\t0.7241\t0.7400\t15300\t44.4812\n",
      "0.1625\t0.5250\t0.6750\t0.6625\t0.6375\t0.7089\t0.6712\t0.6866\t0.7857\t0.7500\t15400\t47.8692\n",
      "0.2500\t0.5625\t0.6625\t0.6835\t0.7237\t0.6800\t0.5714\t0.6667\t0.7018\t0.7021\t15500\t45.8745\n",
      "0.2500\t0.6500\t0.5875\t0.7308\t0.6795\t0.7237\t0.6479\t0.6885\t0.7455\t0.7727\t15600\t43.7128\n",
      "0.2500\t0.4875\t0.5875\t0.8250\t0.7013\t0.7792\t0.5833\t0.7971\t0.7627\t0.6522\t15700\t44.6346\n",
      "0.2375\t0.5375\t0.6500\t0.6250\t0.7179\t0.6364\t0.7639\t0.7015\t0.7458\t0.7115\t15800\t44.1840\n",
      "0.2000\t0.5125\t0.6375\t0.7308\t0.6883\t0.7200\t0.7429\t0.7031\t0.7544\t0.7600\t15900\t41.5692\n",
      "0.2000\t0.5500\t0.6250\t0.7500\t0.7692\t0.7500\t0.6849\t0.7692\t0.7544\t0.7111\t16000\t42.3164\n",
      "0.2500\t0.5875\t0.6582\t0.7089\t0.7089\t0.7632\t0.7500\t0.8088\t0.7742\t0.7609\t16100\t40.1613\n",
      "0.1375\t0.6076\t0.5316\t0.6962\t0.6835\t0.6267\t0.6338\t0.7619\t0.6897\t0.6458\t16200\t49.1107\n",
      "0.2000\t0.5375\t0.5875\t0.7125\t0.7125\t0.8182\t0.7361\t0.8060\t0.6379\t0.7273\t16300\t41.9399\n",
      "0.2000\t0.6125\t0.7750\t0.6125\t0.7125\t0.7403\t0.7467\t0.6462\t0.7018\t0.7556\t16400\t42.1405\n",
      "0.2750\t0.6375\t0.7375\t0.7250\t0.7125\t0.8026\t0.6901\t0.8154\t0.7049\t0.7755\t16500\t38.9754\n",
      "0.1625\t0.6125\t0.7125\t0.6875\t0.6795\t0.7532\t0.6986\t0.7206\t0.8036\t0.8000\t16600\t41.3801\n",
      "0.2500\t0.6000\t0.5875\t0.6709\t0.7215\t0.7027\t0.7500\t0.7705\t0.7586\t0.7674\t16700\t43.2038\n",
      "0.2125\t0.5500\t0.7342\t0.6410\t0.7821\t0.7436\t0.7500\t0.6154\t0.5893\t0.6889\t16800\t44.4377\n",
      "0.2125\t0.5375\t0.6625\t0.6750\t0.6582\t0.6883\t0.7467\t0.6970\t0.7170\t0.8049\t16900\t42.0848\n",
      "0.2125\t0.6125\t0.6250\t0.7468\t0.6795\t0.7467\t0.6986\t0.8116\t0.7455\t0.7826\t17000\t42.0964\n",
      "0.3250\t0.6250\t0.6250\t0.6625\t0.6875\t0.6494\t0.6901\t0.7167\t0.7400\t0.7500\t17100\t43.2635\n",
      "0.2625\t0.6000\t0.6375\t0.6750\t0.6962\t0.7838\t0.7746\t0.7460\t0.8039\t0.7619\t17200\t40.2924\n",
      "0.1750\t0.5500\t0.7125\t0.7089\t0.7273\t0.7600\t0.6571\t0.7937\t0.7455\t0.6364\t17300\t41.7789\n",
      "0.1875\t0.6625\t0.6500\t0.7500\t0.7595\t0.7662\t0.7429\t0.7500\t0.6863\t0.7500\t17400\t40.3501\n",
      "0.1250\t0.6875\t0.6875\t0.7250\t0.8481\t0.7692\t0.8451\t0.8197\t0.7647\t0.7619\t17500\t39.1524\n",
      "0.1500\t0.6000\t0.7375\t0.8125\t0.7692\t0.7733\t0.7887\t0.8000\t0.8214\t0.8333\t17600\t38.3340\n",
      "0.2375\t0.6250\t0.7375\t0.7595\t0.6329\t0.6842\t0.8000\t0.8000\t0.8276\t0.8723\t17700\t39.0741\n",
      "0.2000\t0.5125\t0.7375\t0.7000\t0.6709\t0.8312\t0.7500\t0.7619\t0.8148\t0.8500\t17800\t41.0867\n",
      "0.2000\t0.6750\t0.7125\t0.6750\t0.8052\t0.8493\t0.7826\t0.7049\t0.8214\t0.7708\t17900\t38.9125\n",
      "0.2500\t0.6750\t0.6375\t0.7468\t0.6154\t0.7237\t0.7887\t0.7705\t0.7636\t0.8085\t18000\t39.9187\n",
      "0.2000\t0.5875\t0.6500\t0.6500\t0.6250\t0.7436\t0.7143\t0.7288\t0.7358\t0.6136\t18100\t42.9679\n",
      "0.1500\t0.5750\t0.6125\t0.6875\t0.7500\t0.6835\t0.8493\t0.7385\t0.7273\t0.7234\t18200\t42.4286\n",
      "0.2000\t0.5875\t0.6000\t0.6875\t0.7250\t0.7143\t0.7297\t0.8333\t0.6842\t0.6585\t18300\t41.7022\n",
      "0.1375\t0.5875\t0.7250\t0.7722\t0.7763\t0.6800\t0.8406\t0.7692\t0.6792\t0.8140\t18400\t39.2848\n",
      "0.2375\t0.4750\t0.6250\t0.6203\t0.6923\t0.8267\t0.6338\t0.7500\t0.8679\t0.7619\t18500\t43.0338\n",
      "0.2000\t0.5250\t0.6500\t0.6076\t0.6456\t0.7143\t0.6769\t0.7619\t0.7895\t0.8542\t18600\t43.8758\n",
      "0.2375\t0.6125\t0.7000\t0.7375\t0.6753\t0.7733\t0.8286\t0.7969\t0.8113\t0.7209\t18700\t39.5605\n",
      "0.2375\t0.6125\t0.7625\t0.7179\t0.7143\t0.7467\t0.7027\t0.7313\t0.8000\t0.8261\t18800\t40.9043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2750\t0.7000\t0.8125\t0.8228\t0.7215\t0.7105\t0.8714\t0.7705\t0.7736\t0.7561\t18900\t37.1043\n",
      "0.2250\t0.5375\t0.6375\t0.6375\t0.6709\t0.7662\t0.7808\t0.7424\t0.8103\t0.7234\t19000\t42.4656\n",
      "0.2750\t0.6125\t0.6962\t0.7051\t0.7436\t0.7867\t0.7746\t0.7612\t0.8621\t0.8182\t19100\t37.9216\n",
      "0.2750\t0.6125\t0.6875\t0.7013\t0.7733\t0.7534\t0.7463\t0.8095\t0.7759\t0.8085\t19200\t39.8701\n",
      "0.3125\t0.6375\t0.6875\t0.6750\t0.7625\t0.7532\t0.7361\t0.8060\t0.7692\t0.8537\t19300\t38.4707\n",
      "0.2000\t0.5000\t0.5875\t0.7250\t0.6750\t0.6923\t0.7123\t0.6818\t0.7544\t0.8605\t19400\t43.9810\n",
      "0.1625\t0.6125\t0.6500\t0.7125\t0.7564\t0.8000\t0.8056\t0.7463\t0.7458\t0.7143\t19500\t37.7122\n",
      "0.2375\t0.5500\t0.7875\t0.7125\t0.7468\t0.6974\t0.7534\t0.8413\t0.8333\t0.8182\t19600\t38.7144\n",
      "0.1875\t0.6250\t0.7375\t0.7500\t0.7342\t0.7973\t0.7612\t0.7692\t0.7167\t0.7000\t19700\t38.7801\n",
      "0.2625\t0.5750\t0.6750\t0.7125\t0.7436\t0.7662\t0.7083\t0.7344\t0.7818\t0.7917\t19800\t41.2507\n",
      "0.2375\t0.7500\t0.7875\t0.7500\t0.6625\t0.8816\t0.7826\t0.7969\t0.7736\t0.8163\t19900\t34.9402\n",
      "0.2625\t0.6125\t0.7875\t0.8000\t0.7750\t0.6883\t0.8451\t0.7541\t0.7885\t0.8261\t20000\t35.4717\n",
      "0.2000\t0.6250\t0.6625\t0.7975\t0.7105\t0.8082\t0.7313\t0.7705\t0.7736\t0.8444\t20100\t37.2402\n",
      "0.2250\t0.7375\t0.7250\t0.6835\t0.6709\t0.7333\t0.7639\t0.7576\t0.7818\t0.6531\t20200\t38.7832\n",
      "0.2125\t0.5500\t0.8250\t0.8250\t0.7051\t0.8052\t0.8592\t0.7903\t0.8103\t0.8049\t20300\t35.7474\n",
      "0.2125\t0.6250\t0.7125\t0.7500\t0.8000\t0.8289\t0.7000\t0.7833\t0.8421\t0.7708\t20400\t36.0687\n",
      "0.2375\t0.5750\t0.7125\t0.6250\t0.6974\t0.8108\t0.8630\t0.7606\t0.8438\t0.7200\t20500\t39.1347\n",
      "0.1750\t0.6375\t0.7750\t0.7625\t0.7500\t0.7436\t0.7714\t0.8281\t0.7895\t0.7955\t20600\t38.6948\n",
      "0.1875\t0.5250\t0.6000\t0.7625\t0.7821\t0.7237\t0.7826\t0.7812\t0.8148\t0.7609\t20700\t39.7754\n",
      "0.2875\t0.5250\t0.6500\t0.6375\t0.7875\t0.6494\t0.7237\t0.7206\t0.6774\t0.7333\t20800\t40.6611\n",
      "0.2000\t0.5375\t0.6250\t0.6500\t0.7342\t0.7922\t0.7429\t0.7931\t0.6538\t0.7907\t20900\t41.7519\n",
      "0.2500\t0.6000\t0.7375\t0.7179\t0.7564\t0.7500\t0.7397\t0.7015\t0.8475\t0.6957\t21000\t41.1605\n",
      "0.2125\t0.5250\t0.6625\t0.6709\t0.8182\t0.7432\t0.8000\t0.8361\t0.8269\t0.8780\t21100\t40.0485\n",
      "0.2125\t0.5625\t0.6500\t0.7625\t0.8125\t0.7000\t0.7237\t0.8636\t0.7833\t0.7660\t21200\t37.8896\n",
      "0.3500\t0.6250\t0.6625\t0.7722\t0.7722\t0.7532\t0.7123\t0.7302\t0.8302\t0.6667\t21300\t37.4415\n",
      "0.2500\t0.6750\t0.7250\t0.8000\t0.7949\t0.7867\t0.8028\t0.8333\t0.8182\t0.8889\t21400\t33.9227\n",
      "0.1875\t0.6625\t0.7375\t0.6582\t0.7468\t0.8000\t0.7361\t0.7692\t0.7241\t0.8298\t21500\t38.7814\n",
      "0.2625\t0.5949\t0.6835\t0.6203\t0.7215\t0.7733\t0.7917\t0.9206\t0.7547\t0.8696\t21600\t37.9324\n",
      "0.2000\t0.6250\t0.7500\t0.7625\t0.7750\t0.7143\t0.7600\t0.7164\t0.6316\t0.7333\t21700\t37.6880\n",
      "0.2375\t0.6875\t0.7000\t0.7625\t0.7975\t0.8000\t0.7639\t0.7761\t0.8070\t0.8140\t21800\t35.6603\n",
      "0.2125\t0.6625\t0.7000\t0.7595\t0.7949\t0.7237\t0.7838\t0.7188\t0.6863\t0.7111\t21900\t40.1975\n",
      "0.2375\t0.7750\t0.7625\t0.7750\t0.8987\t0.7821\t0.7746\t0.8030\t0.8421\t0.8000\t22000\t34.2947\n",
      "0.2000\t0.6750\t0.7250\t0.7750\t0.7125\t0.7792\t0.8158\t0.8194\t0.8519\t0.7727\t22100\t35.3338\n",
      "0.1750\t0.6500\t0.8000\t0.7250\t0.7875\t0.8354\t0.6842\t0.7143\t0.7759\t0.7381\t22200\t37.9022\n",
      "0.1625\t0.5000\t0.6203\t0.7089\t0.6795\t0.6800\t0.7361\t0.7273\t0.8167\t0.6341\t22300\t41.9156\n",
      "0.2125\t0.7375\t0.6375\t0.7468\t0.7722\t0.8182\t0.7714\t0.7778\t0.7455\t0.7708\t22400\t40.1936\n",
      "0.2500\t0.6750\t0.6625\t0.7848\t0.7595\t0.8052\t0.7703\t0.6957\t0.8393\t0.9048\t22500\t36.9952\n",
      "0.2000\t0.6375\t0.7375\t0.7625\t0.8052\t0.7162\t0.8028\t0.7941\t0.8103\t0.7826\t22600\t38.3971\n",
      "0.2125\t0.5875\t0.7500\t0.7595\t0.7848\t0.8052\t0.8158\t0.7761\t0.9074\t0.8182\t22700\t35.5909\n",
      "0.2500\t0.6375\t0.6282\t0.8052\t0.7662\t0.7763\t0.7838\t0.7143\t0.8947\t0.7674\t22800\t37.6647\n",
      "0.2125\t0.6000\t0.6875\t0.6962\t0.8481\t0.7273\t0.8611\t0.7273\t0.8727\t0.9070\t22900\t35.9146\n",
      "0.2875\t0.6375\t0.7625\t0.7375\t0.7342\t0.6579\t0.7027\t0.6761\t0.8727\t0.7778\t23000\t38.2100\n",
      "0.3000\t0.6076\t0.6709\t0.8077\t0.8718\t0.8289\t0.7397\t0.8154\t0.7586\t0.7907\t23100\t36.5247\n",
      "0.2000\t0.7250\t0.7000\t0.7750\t0.7722\t0.7632\t0.7534\t0.7857\t0.8000\t0.8125\t23200\t35.7594\n",
      "0.2625\t0.6000\t0.7750\t0.7750\t0.7468\t0.7848\t0.7838\t0.8254\t0.8269\t0.7556\t23300\t37.1176\n",
      "0.2625\t0.6750\t0.6750\t0.7125\t0.7750\t0.8354\t0.7200\t0.7353\t0.7667\t0.7556\t23400\t37.4677\n",
      "0.2000\t0.5875\t0.7375\t0.7875\t0.8077\t0.7632\t0.7324\t0.8182\t0.8302\t0.8444\t23500\t37.4866\n",
      "0.2375\t0.6250\t0.7500\t0.8000\t0.7051\t0.8421\t0.7917\t0.7812\t0.8644\t0.8723\t23600\t35.0049\n",
      "0.2375\t0.6625\t0.7500\t0.7750\t0.7722\t0.7564\t0.7467\t0.8182\t0.6667\t0.7250\t23700\t37.7800\n",
      "0.2875\t0.6500\t0.7375\t0.7500\t0.7722\t0.8533\t0.7778\t0.8788\t0.7833\t0.8600\t23800\t36.1686\n",
      "0.2750\t0.5750\t0.7125\t0.6875\t0.7468\t0.7662\t0.7361\t0.8636\t0.6909\t0.8222\t23900\t39.5135\n",
      "0.2125\t0.6000\t0.7375\t0.7750\t0.8375\t0.7662\t0.7297\t0.8182\t0.8750\t0.8333\t24000\t34.8736\n"
     ]
    }
   ],
   "source": [
    "restore_training = False\n",
    "label_type = \"one_hot\"\n",
    "n_classes = 5\n",
    "seq_length = 50\n",
    "augment = True\n",
    "read_head_num = 4\n",
    "batch_size = 16\n",
    "num_epochs = 100000\n",
    "learning_rate = 1e-3\n",
    "rnn_size = 200\n",
    "image_width = 20\n",
    "image_height = 20\n",
    "rnn_num_layers = 1\n",
    "num_memory_slots = 128\n",
    "memory_vector_dim = 40\n",
    "shift_range = 1\n",
    "write_head_num = 4\n",
    "test_batch_num = 100\n",
    "n_train_classes = 220\n",
    "n_test_classes = 60\n",
    "save_dir = './save/one_shot_learning'\n",
    "tensorboard_dir = './summary/one_shot_learning'\n",
    "model_path = 'LSTM'\n",
    "train(learning_rate, image_width, image_height, n_train_classes, n_test_classes, restore_training, \\\n",
    "         num_epochs, n_classes, batch_size, seq_length, num_memory_slots, augment, save_dir, model_path, tensorboard_dir)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Edit Metadata",
  "colab": {
   "collapsed_sections": [],
   "name": "Project_5_part_1_Student.ipynb",
   "provenance": [
    {
     "file_id": "17BvkhrvTKBi0IMM1Fazl6UVLtm0fb8E7",
     "timestamp": 1573460220489
    },
    {
     "file_id": "1tRHaZoIYsfB16Gh-s_KAX6A41NdP3XKa",
     "timestamp": 1573332369516
    },
    {
     "file_id": "1EfocEfdlVns48iXbXJf7_Jy-v-WCN9NN",
     "timestamp": 1573327062889
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.6 - Learning [learning/conda-5.1.0-py36-gpu]",
   "language": "python",
   "name": "sys_learning36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
