{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKRfNs6ICuLD"
   },
   "source": [
    "* Student Name: Varun Aggarwal \n",
    "* ECE 595 Machine Learning II\n",
    "* Project 3: GAN - Student Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9nfXEi7WC0OA"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e4f5b64885ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Import necessary packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#Import necessary packages\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import adam\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fACNZwo4DBrP"
   },
   "source": [
    "# Part 1: Implementing the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IAKtkDn6DQsy"
   },
   "outputs": [],
   "source": [
    "#Load MNIST data and normalize to [-1, 1]\n",
    "# Fill this in\n",
    "(data_train, _), _ = mnist.load_data()\n",
    "data_train = (data_train*2.0/255.0)-1\n",
    "\n",
    "# The D-dimensional noise vector length\n",
    "latent_dim = 100\n",
    "\n",
    "# Optimizer for discriminator, which will have a higher learning rate than adversarial model\n",
    "def adam_optimizer(lr,beta1):\n",
    "    # FILL THIS IN\n",
    "    return adam(lr,beta1)\n",
    "\n",
    "# Genrerator model\n",
    "def create_generator():\n",
    "    # FILL THIS IN\n",
    "    model = Sequetial()\n",
    "    model.add(Dense(300, input_dim=latent_dim, activation=LeakyReLU(0.1)))\n",
    "    model.add(Dense(600, activation=LeakyReLU(0.1)))\n",
    "    model.add(Dense(1200, activation=LeakyReLU(0.1)))\n",
    "    model.add(Dense(784, activation='tanh'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam_optimizer(1e-4), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Discriminator model\n",
    "def create_discriminator(drop, alpha):\n",
    "    # FILL THIS IN\n",
    "    model = Sequetial()\n",
    "    model.add(Dense(1200, input_dim=784, activation=LeakyReLU(0.1)))\n",
    "    if drop:\n",
    "        model.add(Dropout(alpha))\n",
    "    model.add(Dense(600, activation=LeakyReLU(0.1)))\n",
    "    if drop:\n",
    "        model.add(Dropout(alpha))\n",
    "    model.add(Dense(300, activation=LeakyReLU(0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam_optimizer(2e-4, 0.5), metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "# Create adversarial model\n",
    "def create_gan(discriminator, generator):\n",
    "    # FILL THIS IN\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(latent_dim,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return gan\n",
    "\n",
    "# Creating GAN\n",
    "generator = create_generator()\n",
    "discriminator = create_discriminator(True, 0.5)\n",
    "gan = create_gan(discriminator, generator)\n",
    "\n",
    "# Model and training parameters\n",
    "#ASSIGN VALUES TO THE FOLLOWING VARIABLES\n",
    "epochs = 100000\n",
    "batch_size = 1024 \n",
    "sample_interval = 10000\n",
    "\n",
    "# Array to save training history\n",
    "training_meta_data = np.zeros([epochs, 4])\n",
    "\n",
    "# Training the GAN\n",
    "for e in range(1, epochs+1):\n",
    "\n",
    "    # Generate random noise as input\n",
    "    # FILL THIS IN\n",
    "\n",
    "    # Generate fake MNIST images from generated noise\n",
    "    # FILL THIS IN\n",
    "\n",
    "    # Get a random set of real MNIST images\n",
    "    # FILL THIS IN\n",
    "\n",
    "    # Concatenate real and fake images into a single array (or batch)\n",
    "    # FILL THIS IN\n",
    "\n",
    "    # Assign training labels (assign high probability, but not 1, to real images)\n",
    "    # FILL THIS IN\n",
    "\n",
    "    # Allow discriminator parameters to be updated\n",
    "    # FILL THIS IN\n",
    "\n",
    "    # Train discriminator on batch of real and fake images. Assign loss and accuracy to variable\n",
    "    # FILL THIS IN\n",
    "\n",
    "    # Train adversarial model and try to fool discriminator (with incorrect label) \n",
    "    # by generating a new batch of noise and assign them labels of real data\n",
    "    # FILL THIS IN\n",
    "\n",
    "    # Keep discriminator weights constant while training generator\n",
    "    # FILL THIS IN\n",
    "\n",
    "    # Train GAN (without updating discriminator weights) on new batch of fake images. Assign loss and accuracy to variable\n",
    "    # FILL THIS IN\n",
    "\n",
    "    # Save training status\n",
    "    # Discriminator and model loss\n",
    "    training_meta_data[e-1, 0] = d_loss[0]\n",
    "    training_meta_data[e-1, 1] = gan_loss[0]\n",
    "\n",
    "    # Discriminator and model accuracy\n",
    "    training_meta_data[e-1, 2] = d_loss[1]\n",
    "    training_meta_data[e-1, 3] = gan_loss[1]\n",
    "\n",
    "\n",
    "    # If at sample interval, print training status and save samples\n",
    "    if e % sample_interval == 0:\n",
    "      \n",
    "        # Print training status\n",
    "        print(\"Epoch %d\" %e)\n",
    "        log_mesg = \"%d: [Discriminaotr loss: %f, acc: %f]\" % (e, d_loss[0], d_loss[1])\n",
    "        log_mesg = \"%s  [GAN loss: %f, acc: %f]\" % (log_mesg, gan_loss[0], gan_loss[1])\n",
    "        print(log_mesg)\n",
    "        \n",
    "        # Plot images \n",
    "        r, c = 5, 5\n",
    "\n",
    "        # Create images from the noise (predict the outcome of the noise)\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow((gen_imgs[cnt].reshape(28, 28)), cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hqRJEDeIG9mx"
   },
   "outputs": [],
   "source": [
    "# Plot model loss vs epoch\n",
    "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zUJwhntuHJK8"
   },
   "outputs": [],
   "source": [
    "# Plot accuracy vs epoch\n",
    "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dC_kPLFKHS7c"
   },
   "source": [
    "[4]. Compare and comment on the results of GAN with dropout and without dropout.\n",
    "\n",
    "\n",
    "[5][a]. Comment on importance of hyper-parameter tuning\n",
    "\n",
    "\n",
    "[6]. Answer the following questions:\n",
    "\n",
    "\n",
    "\n",
    "1.   Why does the accuracy of the discriminator remain around 50%? Is this a good trait of the GAN? \n",
    "\n",
    "  ANS: \n",
    "\n",
    "\n",
    "2.   How could this model be modified to produce cleaner (less noisy) images? \n",
    "\n",
    "  ANS: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ZBFSk1RHX5J"
   },
   "source": [
    "# Part 2: Generating samples using trained generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LHaVnENuHcKQ"
   },
   "outputs": [],
   "source": [
    "# Generate ten images from Gaussian noise using the trained generator from Part 1\n",
    "# FILL THIS IN\n",
    "\n",
    "# Re-scale generated images to lie in [0, 1]\n",
    "# FILL THIS IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nak-dm-CIC6r"
   },
   "outputs": [],
   "source": [
    "# Visualize generated noise\n",
    "r, c = 2, 5\n",
    "fig, axs = plt.subplots(r, c)\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow((noise[cnt].reshape(10, 10)), cmap='gray')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "r-Jir5ULIITP"
   },
   "outputs": [],
   "source": [
    "# Visualize generated samples\n",
    "r, c = 2, 5\n",
    "fig, axs = plt.subplots(r, c)\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow((generated_images[cnt].reshape(28, 28)), cmap='gray')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w4I4Q8fhIheQ"
   },
   "source": [
    "# Part 3: Testing accuracy of generated images on ten samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "pHjnlh6dIiMv"
   },
   "outputs": [],
   "source": [
    "# Load mnist classifier and generated images\n",
    "mnist_classifier = load_model('mnist_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "P_BFS0cgInWF"
   },
   "outputs": [],
   "source": [
    "# ASSIGN CLASSES\n",
    "labels = []\n",
    "\n",
    "# Convert integer labels to one-hot labels \n",
    "labels = keras.utils.np_utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# Show classifications\n",
    "# FILL THIS IN \n",
    "\n",
    "# Evaluate accuracy\n",
    "# FILL THIS IN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hxCLMvJnI95c"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project_3_Student.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
